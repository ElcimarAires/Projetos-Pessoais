# -*- coding: utf-8 -*-
"""ELT574 118579 Atividade 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zrkgMz6EDBrViMHlewY95JRmg_ZzLaW6

# **ELT 574 APRENDIZADO DE MÁQUINA**
MATRICULA 118579
  
NOME ELCIMAR AIRES DE BRITO

Utilize o notebook disponibilizado para o problema de classificação multiclasse Fashion MNIST e, ajustando diferentes hiperparâmetros de treinamento, tente atingir 90% de acurácia nas inferências. Apresente o gráfico de treinamento e validação da função de loss. Caso não consiga atingir este nível de precisão, mostre qual foi seu melhor resultado.
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets

# Carregar o conjunto de dados Fashion MNIST
(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()

# Nomes das classes do Fashion MNIST
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Contar a frequência de cada classe no conjunto de dados de teste
unique, counts = np.unique(test_labels, return_counts=True)
class_counts = dict(zip(unique, counts))

# Listar os tipos de amostras e suas frequências
print("Tipos de amostras no conjunto de dados de teste:")
for class_index, count in class_counts.items():
    print(f"{class_names[class_index]}: {count} amostras")

# Plotar as frequências das classes
plt.figure(figsize=(10, 5))
plt.bar(class_names, counts)
plt.xlabel('Classes')
plt.ylabel('Número de amostras')
plt.title('Distribuição das classes no conjunto de dados de teste')
plt.xticks(rotation=45)
plt.show()

"""As classes do Fashion MNIST são:

0: T-shirt/top
1: Trouser
2: Pullover
3: Dress
4: Coat
5: Sandal
6: Shirt
7: Sneaker
8: Bag
9: Ankle boot
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Carregar o conjunto de dados Fashion MNIST
(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()

# Normalizar as imagens
train_images, test_images = train_images / 255.0, test_images / 255.0

# Verificar o shape dos dados
print(train_images.shape, train_labels.shape)
print(test_images.shape, test_labels.shape)

# Construir o modelo
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

# Compilar o modelo
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Treinar o modelo
history = model.fit(train_images, train_labels, epochs=10,
                    validation_data=(test_images, test_labels))

# Avaliar o modelo
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print('\nAcurácia no teste:', test_acc)

# Plotar o gráfico de loss de treinamento e validação
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 1.5])
plt.legend(loc='upper right')
plt.show()

# Plotar acurácia de treinamento e validação
plt.subplot(2, 1, 2)
plt.plot(history.history['accuracy'], label='Acurácia de treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de validação')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend(loc='lower right')
plt.title('Acurácia de Treinamento e Validação')

plt.tight_layout()
plt.show()

# Salvar o modelo treinado
model.save('fashion_mnist_model.h5')

import numpy as np

# Função para prever a classe de uma única imagem
def predict_image(model, image):
    # Adicionar uma dimensão para representar o batch size
    image = np.expand_dims(image, axis=0)
    # Fazer a previsão
    predictions = model.predict(image)
    # Converter logits em probabilidades
    probas = tf.nn.softmax(predictions[0])
    # Classe prevista
    predicted_class = np.argmax(probas)
    return predicted_class, probas

# Escolher uma imagem do conjunto de teste
sample_index = 0  # Você pode mudar este índice para testar outras imagens
sample_image = test_images[sample_index]
sample_label = test_labels[sample_index]

# Fazer a previsão
predicted_class, probas = predict_image(model, sample_image)

# Exibir os resultados
print(f"Etiqueta real: {sample_label}")
print(f"Classe prevista: {predicted_class}")
print(f"Probabilidades: {probas}")

# Plotar a imagem e as probabilidades
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plt.imshow(sample_image.squeeze(), cmap=plt.cm.binary)
plt.title(f"Real: {sample_label} / Previsto: {predicted_class}")

plt.subplot(1,2,2)
plt.bar(range(10), probas)
plt.title("Probabilidades")
plt.show()

"""# **Conclusão**
O modelo treinado para classificação multiclasse usando o conjunto de dados Fashion MNIST atingiu uma acurácia de teste de 90.56%. Abaixo estão os detalhes dos parâmetros utilizados e uma análise do desempenho do modelo.

Detalhamento dos Parâmetros Utilizados
Arquitetura do Modelo:

Camadas de Convolução (Conv2D):
Primeira camada: 32 filtros, tamanho do kernel (3, 3), ativação ReLU.
Segunda camada: 64 filtros, tamanho do kernel (3, 3), ativação ReLU.
Terceira camada: 64 filtros, tamanho do kernel (3, 3), ativação ReLU.
Camadas de Pooling (MaxPooling2D):
Primeira camada: tamanho do pool (2, 2).
Segunda camada: tamanho do pool (2, 2).
Camada de Flatten:
Transforma os mapas de características 2D em vetores 1D.
Camadas Densas (Dense):
Primeira camada: 64 unidades, ativação ReLU.
Segunda camada: 10 unidades (uma para cada classe), sem função de ativação (os logits serão convertidos em probabilidades na função de perda).

"""